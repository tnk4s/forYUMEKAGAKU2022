{"cells":[{"cell_type":"markdown","metadata":{"id":"ho2S8T_yJv1Q"},"source":["# セットアップ"]},{"cell_type":"code","execution_count":3,"metadata":{"id":"rzmcxXjbK9-s","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1688444291959,"user_tz":-540,"elapsed":24090,"user":{"displayName":"田中大智","userId":"05716174105331364617"}},"outputId":"b1d38d19-a322-4da3-9d13-3973798c7a0a"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":2,"metadata":{"id":"Uuviq3qQkUFy","colab":{"base_uri":"https://localhost:8080/"},"outputId":"ef224e67-b7c3-492a-ba24-1883f23687e4","executionInfo":{"status":"ok","timestamp":1688444267877,"user_tz":-540,"elapsed":48820,"user":{"displayName":"田中大智","userId":"05716174105331364617"}}},"outputs":[{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Cloning into 'encoder4editing'...\n","remote: Enumerating objects: 233, done.\u001b[K\n","remote: Counting objects: 100% (233/233), done.\u001b[K\n","remote: Compressing objects: 100% (151/151), done.\u001b[K\n","remote: Total 233 (delta 80), reused 203 (delta 78), pack-reused 0\u001b[K\n","Receiving objects: 100% (233/233), 35.00 MiB | 3.00 MiB/s, done.\n","Resolving deltas: 100% (80/80), done.\n","--2023-07-04 04:15:28--  https://github.com/ninja-build/ninja/releases/download/v1.8.2/ninja-linux.zip\n","Resolving github.com (github.com)... 20.205.243.166\n","Connecting to github.com (github.com)|20.205.243.166|:443... connected.\n","HTTP request sent, awaiting response... 302 Found\n","Location: https://objects.githubusercontent.com/github-production-release-asset-2e65be/1335132/d2f252e2-9801-11e7-9fbf-bc7b4e4b5c83?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20230704%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20230704T041528Z&X-Amz-Expires=300&X-Amz-Signature=abf924f5f89ab1e7e01fa3eea522925db0f34a7ffa6703e5328ff10ac8f59ad3&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=1335132&response-content-disposition=attachment%3B%20filename%3Dninja-linux.zip&response-content-type=application%2Foctet-stream [following]\n","--2023-07-04 04:15:29--  https://objects.githubusercontent.com/github-production-release-asset-2e65be/1335132/d2f252e2-9801-11e7-9fbf-bc7b4e4b5c83?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20230704%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20230704T041528Z&X-Amz-Expires=300&X-Amz-Signature=abf924f5f89ab1e7e01fa3eea522925db0f34a7ffa6703e5328ff10ac8f59ad3&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=1335132&response-content-disposition=attachment%3B%20filename%3Dninja-linux.zip&response-content-type=application%2Foctet-stream\n","Resolving objects.githubusercontent.com (objects.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n","Connecting to objects.githubusercontent.com (objects.githubusercontent.com)|185.199.108.133|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 77854 (76K) [application/octet-stream]\n","Saving to: ‘ninja-linux.zip’\n","\n","ninja-linux.zip     100%[===================>]  76.03K  --.-KB/s    in 0.004s  \n","\n","2023-07-04 04:15:29 (17.7 MB/s) - ‘ninja-linux.zip’ saved [77854/77854]\n","\n","Archive:  ninja-linux.zip\n","  inflating: /usr/local/bin/ninja    \n","update-alternatives: using /usr/local/bin/ninja to provide /usr/bin/ninja (ninja) in auto mode\n","Requirement already satisfied: gdown in /usr/local/lib/python3.10/dist-packages (4.6.6)\n","Collecting gdown\n","  Downloading gdown-4.7.1-py3-none-any.whl (15 kB)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from gdown) (3.12.2)\n","Requirement already satisfied: requests[socks] in /usr/local/lib/python3.10/dist-packages (from gdown) (2.27.1)\n","Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from gdown) (1.16.0)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from gdown) (4.65.0)\n","Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from gdown) (4.11.2)\n","Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->gdown) (2.4.1)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (1.26.16)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (2023.5.7)\n","Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (2.0.12)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (3.4)\n","Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (1.7.1)\n","Installing collected packages: gdown\n","  Attempting uninstall: gdown\n","    Found existing installation: gdown 4.6.6\n","    Uninstalling gdown-4.6.6:\n","      Successfully uninstalled gdown-4.6.6\n","Successfully installed gdown-4.7.1\n"]},{"output_type":"stream","name":"stderr","text":["Downloading...\n","From (uriginal): https://drive.google.com/u/1/uc?id=1Du_8FzOPKJhk6aJmiOBhAWVe3_6vAyET\n","From (redirected): https://drive.google.com/uc?id=1Du_8FzOPKJhk6aJmiOBhAWVe3_6vAyET&confirm=t&uuid=f696bed2-2883-4383-beb3-623bf31103b2\n","To: /content/encoder4editing/pretrained_models/e4e_ffhq_encode.pt\n","100%|██████████| 1.20G/1.20G [00:22<00:00, 53.3MB/s]\n"]},{"output_type":"stream","name":"stdout","text":["--2023-07-04 04:17:19--  http://dlib.net/files/shape_predictor_68_face_landmarks.dat.bz2\n","Resolving dlib.net (dlib.net)... 107.180.26.78\n","Connecting to dlib.net (dlib.net)|107.180.26.78|:80... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 64040097 (61M)\n","Saving to: ‘shape_predictor_68_face_landmarks.dat.bz2’\n","\n","shape_predictor_68_ 100%[===================>]  61.07M  11.1MB/s    in 13s     \n","\n","2023-07-04 04:17:33 (4.63 MB/s) - ‘shape_predictor_68_face_landmarks.dat.bz2’ saved [64040097/64040097]\n","\n","Loading e4e over the pSp framework from checkpoint: pretrained_models/e4e_ffhq_encode.pt\n","Model successfully loaded!\n"]}],"source":["# --- セットアップ ---\n","\n","import os\n","os.chdir('/content')\n","CODE_DIR = 'encoder4editing'\n","\n","!git clone https://github.com/cedro3/encoder4editing.git $CODE_DIR\n","!wget https://github.com/ninja-build/ninja/releases/download/v1.8.2/ninja-linux.zip\n","!sudo unzip ninja-linux.zip -d /usr/local/bin/\n","!sudo update-alternatives --install /usr/bin/ninja ninja /usr/local/bin/ninja 1 --force\n","os.chdir(f'./{CODE_DIR}')\n","\n","from argparse import Namespace\n","import time\n","import os\n","import sys\n","import numpy as np\n","from PIL import Image\n","import torch\n","import torchvision.transforms as transforms\n","\n","sys.path.append(\".\")\n","sys.path.append(\"..\")\n","\n","from utils.common import tensor2im\n","from models.psp import pSp  # we use the pSp framework to load the e4e encoder.\n","\n","%load_ext autoreload\n","%autoreload 2\n","\n","# 学習済みパラメータのダウンロード\n","! pip install --upgrade gdown\n","import os\n","import gdown\n","os.makedirs('pretrained_models', exist_ok=True)\n","gdown.download('https://drive.google.com/u/1/uc?id=1Du_8FzOPKJhk6aJmiOBhAWVe3_6vAyET', 'pretrained_models/e4e_ffhq_encode.pt', quiet=False)\n","\n","# ランドマークデータのダウンロード\n","! wget http://dlib.net/files/shape_predictor_68_face_landmarks.dat.bz2\n","! bzip2 -dk shape_predictor_68_face_landmarks.dat.bz2\n","\n","# モデルに学習済みパラメータをロード\n","model_path = 'pretrained_models/e4e_ffhq_encode.pt'  ####\n","ckpt = torch.load(model_path, map_location='cpu')\n","opts = ckpt['opts']\n","opts['checkpoint_path'] = model_path\n","opts= Namespace(**opts)\n","net = pSp(opts)\n","net.eval()\n","net.cuda()\n","print('Model successfully loaded!')"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":460,"status":"ok","timestamp":1688444302012,"user":{"displayName":"田中大智","userId":"05716174105331364617"},"user_tz":-540},"id":"mcgdr05kL-5X","outputId":"9c0b77ff-a6fb-4594-a6c0-ab4173d5b580"},"outputs":[{"output_type":"stream","name":"stdout","text":["/content/encoder4editing\n"]}],"source":["! pwd"]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":456,"status":"ok","timestamp":1688444305004,"user":{"displayName":"田中大智","userId":"05716174105331364617"},"user_tz":-540},"id":"9kq0dT7GL-Ly","outputId":"3cb50626-ceff-4305-d2b5-07d69424454d"},"outputs":[{"output_type":"stream","name":"stdout","text":["configs\t\timages\t\t   README.md\n","criteria\tLICENSE\t\t   scripts\n","datasets\tmetrics\t\t   shape_predictor_68_face_landmarks.dat\n","docs\t\tmodels\t\t   shape_predictor_68_face_landmarks.dat.bz2\n","e4e_demo.ipynb\tmyimages\t   training\n","editings\toptions\t\t   utils\n","environment\tpretrained_models\n"]}],"source":["! mkdir /content/encoder4editing/myimages\n","! ls"]},{"cell_type":"markdown","metadata":{"id":"o6oqf8JwzK0K"},"source":["# 実行\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"iUhFQpAyNG0x","outputId":"58afcb9e-72c5-4bf4-bfcb-cc212cd6c5f9"},"outputs":[{"output_type":"stream","name":"stdout","text":["waiting...\n","Mounted at /content/drive/\n","Mounted at /content/drive/\n","Mounted at /content/drive/\n","Mounted at /content/drive/\n","Mounted at /content/drive/\n","Mounted at /content/drive/\n","Mounted at /content/drive/\n","Mounted at /content/drive/\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 1/1 [00:02<00:00,  2.37s/it]\n","100%|██████████| 1/1 [00:06<00:00,  6.52s/it]\n","-5 -> max: 100%|██████████| 45/45 [00:02<00:00, 16.67it/s]\n"]},{"output_type":"stream","name":"stdout","text":["waiting...\n","Mounted at /content/drive/\n","Mounted at /content/drive/\n","Mounted at /content/drive/\n","Mounted at /content/drive/\n","Mounted at /content/drive/\n","Mounted at /content/drive/\n","Mounted at /content/drive/\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 1/1 [00:01<00:00,  1.17s/it]\n","100%|██████████| 1/1 [00:00<00:00,  4.24it/s]\n","-5 -> max: 100%|██████████| 45/45 [00:02<00:00, 16.47it/s]\n"]},{"output_type":"stream","name":"stdout","text":["waiting...\n","Mounted at /content/drive/\n","Mounted at /content/drive/\n","Mounted at /content/drive/\n","Mounted at /content/drive/\n","Mounted at /content/drive/\n","Mounted at /content/drive/\n","Mounted at /content/drive/\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 1/1 [00:01<00:00,  1.21s/it]\n","100%|██████████| 1/1 [00:00<00:00,  4.20it/s]\n","-5 -> max: 100%|██████████| 45/45 [00:02<00:00, 15.60it/s]\n"]},{"output_type":"stream","name":"stdout","text":["waiting...\n","Mounted at /content/drive/\n","Mounted at /content/drive/\n","Mounted at /content/drive/\n","Mounted at /content/drive/\n","Mounted at /content/drive/\n","Mounted at /content/drive/\n","Mounted at /content/drive/\n","Mounted at /content/drive/\n","Mounted at /content/drive/\n","Mounted at /content/drive/\n","Mounted at /content/drive/\n","Mounted at /content/drive/\n","Mounted at /content/drive/\n","Mounted at /content/drive/\n","Mounted at /content/drive/\n","Mounted at /content/drive/\n","Mounted at /content/drive/\n","Mounted at /content/drive/\n","Mounted at /content/drive/\n","Mounted at /content/drive/\n","Mounted at /content/drive/\n","Mounted at /content/drive/\n","Mounted at /content/drive/\n","Mounted at /content/drive/\n","Mounted at /content/drive/\n"]}],"source":["#! rm /content/StyleCariGAN/examples/my_samples/myFace.pt\n","#! cp -f /content/drive/MyDrive/api_test/myFace.png /content/StyleCariGAN/examples/my_samples/myFace.png\n","from google.colab import drive\n","#drive.mount('/content/drive')\n","\n","import time\n","import subprocess\n","import os\n","import shutil\n","from tqdm import tqdm\n","from editings import latent_editor\n","from tqdm import trange\n","import matplotlib.pyplot as plt\n","from PIL import Image\n","import dlib\n","from utils.alignment import align_face\n","\n","def run_alignment(image_path):\n","    predictor = dlib.shape_predictor(\"shape_predictor_68_face_landmarks.dat\")\n","    aligned_image = align_face(filepath=image_path, predictor=predictor)\n","    return aligned_image\n","\n","def display_pic(folder):\n","    fig = plt.figure(figsize=(30, 40))\n","    files = os.listdir(folder)\n","    files.sort()\n","    for i, file in enumerate(files):\n","        img = Image.open(folder+'/'+file)\n","        images = np.asarray(img)\n","        ax = fig.add_subplot(10, 10, i+1, xticks=[], yticks=[])\n","        image_plt = np.array(images)\n","        ax.imshow(image_plt)\n","        ax.set_xlabel(folder+'/'+file, fontsize=15)\n","    plt.show()\n","    plt.close()\n","\n","\n","for i in range(10):\n","    print('waiting...')\n","    end_flag = False\n","    for j in range(60):\n","        drive.mount('/content/drive/',force_remount=True)\n","        time.sleep(10)\n","        if os.path.exists('/content/drive/MyDrive/api_test/myFace.png'):\n","            shutil.copy('/content/drive/MyDrive/api_test/myFace.png', '/content/encoder4editing/myimages/myFace.png')\n","            os.remove('/content/drive/MyDrive/api_test/myFace.png')\n","            break\n","        if j == 29:\n","            end_flag = True\n","    if end_flag:\n","        break\n","    # --- 顔画像の切り出し ---\n","    if os.path.isdir('align'):\n","        shutil.rmtree('align')\n","    os.makedirs('align', exist_ok=True)\n","\n","    path = './myimages'\n","    files = sorted(os.listdir(path))\n","    for i, file in enumerate(tqdm(files)):\n","        if file=='.ipynb_checkpoints':\n","            continue\n","        input_image = run_alignment(path+'/'+file)\n","        input_image.resize((256,256))\n","        input_image.save('./align/'+file)\n","\n","\n","    # --- 潜在変数の推定 ---\n","\n","    if os.path.isdir('vec_pic'):\n","        shutil.rmtree('vec_pic')\n","    os.makedirs('vec_pic', exist_ok=True)\n","\n","    if os.path.isdir('vec'):\n","        shutil.rmtree('vec')\n","    os.makedirs('vec', exist_ok=True)\n","\n","    img_transforms = transforms.Compose([\n","            transforms.Resize((256, 256)),\n","            transforms.ToTensor(),\n","            transforms.Normalize([0.5, 0.5, 0.5], [0.5, 0.5, 0.5])])\n","\n","    path = './align'\n","    files = sorted(os.listdir(path))\n","    for i, file in enumerate(tqdm(files)):\n","      if file=='.ipynb_checkpoints':\n","        continue\n","      input_image = Image.open(path+'/'+file)\n","      transformed_image = img_transforms(input_image)\n","      with torch.no_grad():\n","        images, latents = net(transformed_image.unsqueeze(0).to('cuda').float(), randomize_noise=False, return_latents=True)\n","        result_image, latent = images[0], latents[0]\n","        tensor2im(result_image).save('./vec_pic/'+file) # vec_pic 保存\n","        torch.save(latents, './vec/'+file[:-4]+'.pt') # vec  保存\n","\n","    # --- 元画像と生成画像の表示 ---\n","    display_pic('align')\n","    display_pic('vec_pic')\n","\n","    latent = \"myFace.pt\"\n","    direction = \"age\"\n","    min = -50\n","    max = 40\n","\n","    # --- 静止画の生成 ---\n","    if os.path.isdir('pic'):\n","        shutil.rmtree('pic')\n","    os.makedirs('pic', exist_ok=True)\n","\n","    folder = 'vec'\n","    latents = torch.load(folder+'/'+latent)\n","    editor = latent_editor.LatentEditor(net.decoder, False)\n","\n","    interfacegan_directions = {\n","            'age': 'editings/interfacegan_directions/age.pt',\n","            'smile': 'editings/interfacegan_directions/smile.pt',\n","            'pose': 'editings/interfacegan_directions/pose.pt',\n","            'age+pose':  'editings/interfacegan_directions/age+pose.pt'\n","        }\n","\n","    interfacegan_direction = torch.load(interfacegan_directions[direction]).cuda()\n","    cnt = 0\n","    \"\"\"\n","    for i in trange(0, min, -1, desc='0 -> min'):\n","        result = editor.apply_interfacegan(latents, interfacegan_direction, factor=i).resize((512,512))\n","        result.save('./pic/'+str(cnt).zfill(6)+'.jpg')\n","        cnt +=1\n","\n","    for i in trange(min, max, desc='min -> max'):\n","        result = editor.apply_interfacegan(latents, interfacegan_direction, factor=i).resize((512,512))\n","        result.save('./pic/'+str(cnt).zfill(6)+'.jpg')\n","        cnt +=1\n","\n","    for i in trange(max, 0, -1, desc='max -> 0'):\n","        result = editor.apply_interfacegan(latents, interfacegan_direction, factor=i).resize((512,512))\n","        result.save('./pic/'+str(cnt).zfill(6)+'.jpg')\n","        cnt +=1\n","    \"\"\"\n","    for i in trange(-5, max, desc='-5 -> max'):\n","        if i%2 == 0:\n","          result = editor.apply_interfacegan(latents, interfacegan_direction, factor=i).resize((512,512))\n","          result.save('./pic/'+str(cnt).zfill(6)+'.jpg')\n","          cnt +=1\n","\n","    # --- mp4動画の作成 ---\n","\n","    # 既に output.mp4 があれば削除する\n","    if os.path.exists('./output.mp4'):\n","      os.remove('./output.mp4')\n","\n","    # pic フォルダーの静止画から動画を作成\n","#! ffmpeg -r 30 -i pic/%6d.jpg -vcodec libx264 -pix_fmt yuv420p output.mp4\n","\n","    subprocess.run([\"ffmpeg\", \"-r\", \"30\", \"-i\", \"pic/%6d.jpg\", \"-vcodec\", \"libx264\", \"-pix_fmt\", \"yuv420p\", \"output.mp4\"])\n","\n","    # movieフォルダへ名前を付けてコピー\n","    os.makedirs('movie', exist_ok=True)\n","    shutil.copy('output.mp4', 'movie/'+direction+'_'+latent[:-3]+'.mp4')\n","    shutil.copy('output.mp4', '/content/drive/MyDrive/api_test/result.mp4')\n","    time.sleep(10)"]}],"metadata":{"accelerator":"GPU","colab":{"provenance":[{"file_id":"https://github.com/cedro3/encoder4editing/blob/main/e4e_demo.ipynb","timestamp":1658295656971}]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.9"},"gpuClass":"standard"},"nbformat":4,"nbformat_minor":0}